{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv+1Tr+B3uIBg1UjD66AHu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-arain/CST383Project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyRpTVQMGBFY"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Feb  7 12:13:29 2021\n",
        "\n",
        "@author: Robert Meis\n",
        "@team Members: Jason Contreras, Mohammad Arain\n",
        "CST-383 Project: Spam vs. Ham Classifier \n",
        "References: https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html\n",
        "https://pandas.pydata.org/ (multiple pages)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "df = pd.read_csv('spam_ham_dataset.csv') #keep both the .csv file and this file in the same folder or update file path\n",
        "df0 = df; #copy df in case df gets modified incorrectly\n",
        "\n",
        "df.columns = ['number', 'label', 'subject', 'label_num'] #drop 'number' (= bias) and 'label' (not needed) columns\n",
        "df.drop(['number', 'label'], axis=1, inplace=True) #\n",
        "\n",
        "#extract label and target vectors\n",
        "X = df['subject'].str.strip('Subject: ') #X = labels vector. Strip word 'Subject: ' which appears in front of each email subject (not needed/biasing)\n",
        "y = df['label_num'] #target vector\n",
        "\n",
        "#weight words using tfidVectorizer for X_train and X_test\n",
        "vec = TfidfVectorizer()\n",
        "X = vec.fit_transform(X)\n",
        "X = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
        "\n",
        "#separate X and y into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "#use kNN\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test[:50])\n",
        "\n",
        "print(predictions, y_test[:50])\n",
        "\n",
        "'''\n",
        "#print(X_train.shape, y_train.shape)\n",
        "#use Naive-Bayes (testing)\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(y_test)\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}